## Project Description
This project aims to develop a real-time face emotion recognition system using computer vision and deep learning techniques. The system captures live video from a camera feed, detects faces within each frame, and accurately predicts the emotional state of the individuals in real-time. Emotions such as anger, disgust, fear, happiness, neutrality, sadness, and surprise are classified. The project involves preprocessing video frames, implementing a Convolutional LSTM (ConvLSTM) neural network for emotion prediction, and overlaying the predicted emotion on the video feed. This practical application can find use in various domains, including human-computer interaction, sentiment analysis, and user experience enhancement. It represents an intermediate-level project that demonstrates proficiency in computer vision, deep learning, and real-time applications.

## Files Description 
- The **[EmotionDetection.ipynb](https://github.com/KhushiDusad/EmotionDetection/blob/main/EmotionDetection.ipynb)** file shows the creation of the Facial Emotion Recognition Model.
- The **[Face Emotion Recognition.ipynb](https://github.com/KhushiDusad/EmotionDetection/blob/main/Face%20Emotion%20Recognition.ipynb)** file shows how to load the model and use it for predicting emotions of images and live video.
- This is the link to the dataset used for training and testing the model: **[dataset](https://www.dropbox.com/s/nilt43hyl1dx82k/dataset.zip?dl=0 )**
- The images used for making predictions later on are provided in the **Test Images** folder
